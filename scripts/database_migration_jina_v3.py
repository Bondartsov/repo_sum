#!/usr/bin/env python3
"""
Database Migration Script –¥–ª—è Jina v3
–ü–æ–ª–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π Qdrant —Å 384d –Ω–∞ 1024d –≤–µ–∫—Ç–æ—Ä—ã
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
from dataclasses import dataclass

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from qdrant_client import QdrantClient
    from qdrant_client.http.models import (
        VectorParams, Distance, OptimizersConfig, HnswConfig,
        ScalarQuantization, ScalarQuantizationConfig, QuantizationType,
        PayloadSchemaType, CreateCollection, CollectionInfo
    )
    from config import get_config
    from rag.vector_store import QdrantVectorStore
    from rag.embedder import CPUEmbedder
    from file_scanner import FileScanner
    from code_chunker import CodeChunker
    from utils import setup_logging
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üîß Make sure you're running from the project root directory")
    sys.exit(1)

# Setup logging
logger = logging.getLogger(__name__)

@dataclass
class MigrationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
    old_collection: str = "code_chunks"
    new_collection: str = "repo_sum_v3"
    old_dimension: int = 384
    new_dimension: int = 1024
    backup_enabled: bool = True
    progress_reporting: bool = True
    batch_size: int = 32
    retry_attempts: int = 3

class JinaV3DatabaseMigration:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ database –Ω–∞ Jina v3"""
    
    def __init__(self, config: MigrationConfig):
        self.config = config
        self.client = None
        self.vector_store = None
        self.embedder = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._initialize_components()
    
    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant –∫–ª–∏–µ–Ω—Ç–∞ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            app_config = get_config()
            
            # Qdrant –∫–ª–∏–µ–Ω—Ç
            self.client = QdrantClient(
                host=os.getenv("QDRANT_HOST", "localhost"),
                port=int(os.getenv("QDRANT_PORT", "6333")),
                prefer_grpc=os.getenv("QDRANT_PREFER_GRPC", "true").lower() == "true"
            )
            
            # Vector Store
            self.vector_store = QdrantVectorStore(app_config.rag.vector_store)
            
            # Embedder (Jina v3)
            self.embedder = CPUEmbedder(app_config.rag.embeddings)
            
            logger.info("‚úÖ Database migration components initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize components: {e}")
            raise
    
    def check_collections_status(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π"""
        status = {}
        
        try:
            collections = self.client.get_collections().collections
            existing_names = [col.name for col in collections]
            
            status["old_collection_exists"] = self.config.old_collection in existing_names
            status["new_collection_exists"] = self.config.new_collection in existing_names
            
            logger.info(f"üìä Collection status: old={status['old_collection_exists']}, new={status['new_collection_exists']}")
            
            return status
            
        except Exception as e:
            logger.error(f"‚ùå Failed to check collections: {e}")
            raise
    
    def backup_old_collection(self) -> Optional[str]:
        """–°–æ–∑–¥–∞—Ç—å backup —Å—Ç–∞—Ä–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        if not self.config.backup_enabled:
            logger.info("‚ö†Ô∏è Backup disabled, skipping...")
            return None
        
        backup_name = f"{self.config.old_collection}_backup_{int(time.time())}"
        
        try:
            # –°–æ–∑–¥–∞–µ–º snapshot –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            response = self.client.create_snapshot(collection_name=self.config.old_collection)
            logger.info(f"‚úÖ Created backup snapshot: {response}")
            return backup_name
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Backup failed (non-critical): {e}")
            return None
    
    def delete_old_collection(self) -> bool:
        """–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        try:
            status = self.check_collections_status()
            
            if not status["old_collection_exists"]:
                logger.info(f"‚úÖ Old collection '{self.config.old_collection}' doesn't exist, nothing to delete")
                return True
            
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏—è
            if not self._confirm_deletion():
                logger.info("‚ùå Deletion cancelled by user")
                return False
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            self.client.delete_collection(self.config.old_collection)
            logger.info(f"‚úÖ Deleted old collection: {self.config.old_collection}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to delete old collection: {e}")
            return False
    
    def create_new_collection(self) -> bool:
        """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å 1024d –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        try:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 1024d
            vector_config = VectorParams(
                size=self.config.new_dimension,
                distance=Distance.COSINE,
                hnsw_config=HnswConfig(
                    m=16,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è 1024d
                    ef_construct=200,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
                    full_scan_threshold=10000,  # CPU-friendly
                    max_indexing_threads=0  # Auto
                ),
                on_disk=True  # –î–ª—è –±–æ–ª—å—à–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            )
            
            # –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            optimizers_config = OptimizersConfig(
                deleted_threshold=0.2,
                vacuum_min_vector_number=1000,
                default_segment_number=0,  # Auto
                max_segment_size=None,  # Auto
                memmap_threshold=None,  # Auto
                indexing_threshold=20000,
                flush_interval_sec=5,
                max_optimization_threads=1  # CPU-conservative
            )
            
            quantization_config = ScalarQuantization(
                scalar=ScalarQuantizationConfig(
                    type=QuantizationType.INT8,
                    quantile=0.99,
                    always_ram=False  # –î–∏—Å–∫ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
                )
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            self.client.create_collection(
                collection_name=self.config.new_collection,
                vectors_config=vector_config,
                optimizers_config=optimizers_config,
                quantization_config=quantization_config
            )
            
            logger.info(f"‚úÖ Created new collection: {self.config.new_collection} (1024d)")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è
            collection_info = self.client.get_collection(self.config.new_collection)
            logger.info(f"üìä Collection info: {collection_info.config}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create new collection: {e}")
            return False
    
    def validate_collection_structure(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            collection_info = self.client.get_collection(self.config.new_collection)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            vector_size = collection_info.config.params.vectors.size
            if vector_size != self.config.new_dimension:
                logger.error(f"‚ùå Wrong vector dimension: {vector_size}, expected: {self.config.new_dimension}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º distance metric
            distance = collection_info.config.params.vectors.distance
            if distance != Distance.COSINE:
                logger.error(f"‚ùå Wrong distance metric: {distance}, expected: COSINE")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º HNSW –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            hnsw = collection_info.config.params.vectors.hnsw_config
            if hnsw.m != 16:
                logger.warning(f"‚ö†Ô∏è HNSW m parameter: {hnsw.m}, recommended: 16")
            
            logger.info("‚úÖ Collection structure validation passed")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Collection validation failed: {e}")
            return False
    
    def perform_full_reindexing(self, repo_path: str) -> bool:
        """–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å Jina v3"""
        try:
            logger.info(f"üîÑ Starting full reindexing: {repo_path}")
            
            # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            scanner = FileScanner()
            files = scanner.scan_files(repo_path)
            logger.info(f"üìÅ Found {len(files)} files to index")
            
            if not files:
                logger.warning("‚ö†Ô∏è No files found to index")
                return True
            
            # Chunking –∫–æ–¥–∞
            chunker = CodeChunker()
            all_chunks = []
            
            for file_info in files:
                try:
                    chunks = chunker.chunk_file(file_info)
                    all_chunks.extend(chunks)
                    
                    if self.config.progress_reporting and len(all_chunks) % 50 == 0:
                        logger.info(f"üîÑ Processed {len(all_chunks)} chunks...")
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to chunk file {file_info.path}: {e}")
                    continue
            
            logger.info(f"üìä Total chunks to index: {len(all_chunks)}")
            
            # –ë–∞—Ç—á–µ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
            success_count = 0
            failed_count = 0
            
            for i in range(0, len(all_chunks), self.config.batch_size):
                batch = all_chunks[i:i + self.config.batch_size]
                
                try:
                    # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–∞—Ç—á–∞ —Å retry –ª–æ–≥–∏–∫–æ–π
                    self._index_batch_with_retry(batch)
                    success_count += len(batch)
                    
                    if self.config.progress_reporting:
                        progress = (i + len(batch)) / len(all_chunks) * 100
                        logger.info(f"üîÑ Progress: {progress:.1f}% ({success_count}/{len(all_chunks)})")
                        
                except Exception as e:
                    logger.error(f"‚ùå Failed to index batch {i//self.config.batch_size}: {e}")
                    failed_count += len(batch)
                    continue
            
            logger.info(f"‚úÖ Reindexing completed: {success_count} success, {failed_count} failed")
            return failed_count == 0
            
        except Exception as e:
            logger.error(f"‚ùå Full reindexing failed: {e}")
            return False
    
    def _index_batch_with_retry(self, chunks: List) -> bool:
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±–∞—Ç—á–∞ —Å retry –ª–æ–≥–∏–∫–æ–π"""
        for attempt in range(self.config.retry_attempts):
            try:
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ embeddings
                texts = [chunk.content for chunk in chunks]
                
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ task="retrieval.passage" –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                embeddings = self.embedder.embed_texts(texts, task="retrieval.passage")
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–æ—á–µ–∫ –¥–ª—è Qdrant
                points = []
                for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                    point = {
                        "id": len(points) + int(time.time() * 1000000) + i,  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                        "vector": embedding.tolist(),
                        "payload": {
                            "content": chunk.content,
                            "file_path": chunk.file_path,
                            "language": chunk.language,
                            "chunk_type": chunk.chunk_type,
                            "start_line": chunk.start_line,
                            "end_line": chunk.end_line
                        }
                    }
                    points.append(point)
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Qdrant
                self.client.upsert(
                    collection_name=self.config.new_collection,
                    points=points
                )
                
                return True
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Attempt {attempt + 1}/{self.config.retry_attempts} failed: {e}")
                if attempt == self.config.retry_attempts - 1:
                    raise
                time.sleep(2 ** attempt)  # Exponential backoff
        
        return False
    
    def _confirm_deletion(self) -> bool:
        """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            response = input(f"\n‚ö†Ô∏è This will DELETE the collection '{self.config.old_collection}'. Continue? (y/N): ")
            return response.lower() in ['y', 'yes']
        except KeyboardInterrupt:
            return False
    
    def get_migration_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–∏–≥—Ä–∞—Ü–∏–∏"""
        try:
            stats = {}
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if self.config.new_collection:
                try:
                    collection_info = self.client.get_collection(self.config.new_collection)
                    stats["new_collection"] = {
                        "name": self.config.new_collection,
                        "vectors_count": collection_info.vectors_count,
                        "indexed_vectors_count": collection_info.indexed_vectors_count,
                        "points_count": collection_info.points_count,
                        "dimension": self.config.new_dimension
                    }
                except:
                    stats["new_collection"] = {"error": "Collection not found"}
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats["migration"] = {
                "from_model": "BAAI/bge-small-en-v1.5",
                "to_model": "jinaai/jina-embeddings-v3",
                "from_dimension": self.config.old_dimension,
                "to_dimension": self.config.new_dimension,
                "timestamp": time.time()
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get migration statistics: {e}")
            return {"error": str(e)}

def main():
    """Main function –¥–ª—è database migration"""
    parser = argparse.ArgumentParser(description="Jina v3 Database Migration")
    parser.add_argument("--action", choices=["migrate", "rollback", "status", "reindex"], 
                       required=True, help="Migration action")
    parser.add_argument("--repo-path", type=str, help="Repository path for reindexing")
    parser.add_argument("--batch-size", type=int, default=32, help="Batch size for indexing")
    parser.add_argument("--no-backup", action="store_true", help="Skip backup creation")
    parser.add_argument("--force", action="store_true", help="Force operation without confirmation")
    
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(level=logging.INFO)
    
    # Migration config
    migration_config = MigrationConfig(
        backup_enabled=not args.no_backup,
        batch_size=args.batch_size
    )
    
    migration = JinaV3DatabaseMigration(migration_config)
    
    try:
        if args.action == "status":
            print("üìä Migration Status:")
            status = migration.check_collections_status()
            stats = migration.get_migration_statistics()
            print(json.dumps({"status": status, "stats": stats}, indent=2))
            
        elif args.action == "migrate":
            print("üöÄ Starting Jina v3 Migration...")
            
            # Backup (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            migration.backup_old_collection()
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if not migration.delete_old_collection():
                print("‚ùå Migration failed at deletion step")
                return 1
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if not migration.create_new_collection():
                print("‚ùå Migration failed at creation step")
                return 1
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if not migration.validate_collection_structure():
                print("‚ùå Migration failed at validation step")
                return 1
            
            print("‚úÖ Database migration completed successfully!")
            
            # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å)
            if args.repo_path:
                print(f"üîÑ Starting reindexing: {args.repo_path}")
                if migration.perform_full_reindexing(args.repo_path):
                    print("‚úÖ Reindexing completed successfully!")
                else:
                    print("‚ö†Ô∏è Reindexing completed with errors")
            
        elif args.action == "reindex":
            if not args.repo_path:
                print("‚ùå --repo-path required for reindexing")
                return 1
            
            print(f"üîÑ Starting reindexing: {args.repo_path}")
            if migration.perform_full_reindexing(args.repo_path):
                print("‚úÖ Reindexing completed successfully!")
            else:
                print("‚ö†Ô∏è Reindexing completed with errors")
                
        elif args.action == "rollback":
            print("üîÑ Rollback not implemented in this script")
            print("üîß Use: bash backups/migration_backup_*/rollback_migration.sh")
            
    except KeyboardInterrupt:
        print("\n‚ùå Migration interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"‚ùå Migration failed: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
