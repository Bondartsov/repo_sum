"""
–°–µ—Ä–≤–∏—Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã.

–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º
–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
"""

import logging
import time
import threading
from typing import List, Dict, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass

import numpy as np
from rich.console import Console
from rich.table import Table
from rich.syntax import Syntax
from rich.panel import Panel

from config import Config
from .embedder import CPUEmbedder
from .vector_store import QdrantVectorStore
from .exceptions import VectorStoreException

logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É"""
    chunk_id: str
    file_path: str
    file_name: str
    chunk_name: str
    chunk_type: str
    language: str
    start_line: int
    end_line: int
    score: float
    content: str
    metadata: Dict[str, Any]


class SearchService:
    """
    –°–µ—Ä–≤–∏—Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É.
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
    - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º —á–∞–Ω–∫–æ–≤
    - –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Rich UI
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    
    def __init__(self, config: Config, silent_mode: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
            silent_mode: –û—Ç–∫–ª—é—á–∏—Ç—å –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ (–¥–ª—è web UI)
        """
        self.config = config
        self.console = Console() if not silent_mode else None
        self.silent_mode = silent_mode
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.embedder = CPUEmbedder(config.rag.embeddings, config.rag.parallelism)
        self.vector_store = QdrantVectorStore(config.rag.vector_store)
        
        # Thread-safe –∫—ç—à –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º–∏
        self._query_cache = {}
        self._cache_lock = threading.RLock()  # RLock –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
        self._cache_max_size = config.rag.query_engine.cache_max_entries
        self._cache_ttl = config.rag.query_engine.cache_ttl_seconds
        
        # Thread-safe —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–∞ —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
        self._stats_lock = threading.RLock()
        self.stats = {
            'total_queries': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'total_search_time': 0.0,
            'avg_results_per_query': 0.0,
            'last_query_time': None
        }
        
        logger.info("SearchService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å thread-safe –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π")
    
    async def search(
        self,
        query: str,
        top_k: int = 10,
        language_filter: Optional[str] = None,
        chunk_type_filter: Optional[str] = None,
        min_score: Optional[float] = None,
        file_path_filter: Optional[str] = None
    ) -> List[SearchResult]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            language_filter: –§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
            chunk_type_filter: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É —á–∞–Ω–∫–∞ (class, function, etc.)
            min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            file_path_filter: –§–∏–ª—å—Ç—Ä –ø–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–¥—Å—Ç—Ä–æ–∫–∏)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        """
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cache_key = self._generate_cache_key(
                query, top_k, language_filter, chunk_type_filter, min_score, file_path_filter
            )
            
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                self._update_stats_safely(cache_hits_incr=1)
                logger.debug(f"–ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –∫—ç—à–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}...")
                return cached_result
            
            self._update_stats_safely(cache_misses_incr=1)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            embed_start = time.time()
            query_embeddings = self.embedder.embed_texts([query])
            embed_time = time.time() - embed_start
            
            if query_embeddings is None or len(query_embeddings) == 0:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
                return []
            
            query_vector = query_embeddings[0]
            logger.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ {embed_time:.3f}s")
            
            # –°—Ç—Ä–æ–∏–º —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è Qdrant
            filters = self._build_search_filters(
                language_filter, chunk_type_filter, file_path_filter
            )
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            search_start = time.time()
            sparse_vector = None
            if self.config.rag.query_engine.use_hybrid:
                try:
                    from .sparse_encoder import SparseEncoder
                    encoder = SparseEncoder()
                    sparse_vector = encoder.encode([query])[0]
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ sparse-–≤–µ–∫—Ç–æ—Ä–∞: {e}")
            raw_results = await self.vector_store.search(
                query_vector=query_vector,
                top_k=top_k * 2,  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                filters=filters,
                use_hybrid=self.config.rag.query_engine.use_hybrid,
                sparse_vector=sparse_vector
            )
            search_time = time.time() - search_start
            
            logger.debug(f"–ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {search_time:.3f}s, –Ω–∞–π–¥–µ–Ω–æ {len(raw_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            effective_min_score = min_score if min_score is not None else self.config.rag.query_engine.score_threshold
            processed_results = self._process_search_results(
                raw_results, effective_min_score
            )
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º MMR –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if self.config.rag.query_engine.mmr_enabled and len(processed_results) > top_k:
                processed_results = self._apply_mmr_ranking(
                    processed_results, query_vector, top_k
                )
            else:
                processed_results = processed_results[:top_k]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self._save_to_cache(cache_key, processed_results)
            
            # Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            total_time = time.time() - start_time
            self._update_stats_safely(
                total_queries_incr=1,
                total_search_time_incr=total_time,
                last_query_time=datetime.utcnow().isoformat()
            )
            
            logger.info(
                f"–ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: '{query}' -> {len(processed_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {total_time:.3f}s"
            )
            
            return processed_results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            raise VectorStoreException(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞: {e}")
    
    def _build_search_filters(
        self,
        language_filter: Optional[str],
        chunk_type_filter: Optional[str],
        file_path_filter: Optional[str]
    ) -> Optional[Dict[str, Any]]:
        """–°—Ç—Ä–æ–∏—Ç —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ Qdrant"""
        filters = {}
        
        if language_filter:
            filters['language'] = language_filter.lower()
        
        if chunk_type_filter:
            filters['chunk_type'] = chunk_type_filter
        
        if file_path_filter:
            # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –ø—É—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫—É
            filters['file_path'] = file_path_filter
        
        return filters if filters else None
    
    def _process_search_results(
        self, 
        raw_results: List[Dict[str, Any]], 
        min_score: float
    ) -> List[SearchResult]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—ã—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ SearchResult –æ–±—ä–µ–∫—Ç—ã"""
        processed = []
        
        for result in raw_results:
            try:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É —Å–∫–æ—Ä—É
                if result['score'] < min_score:
                    continue
                
                payload = result.get('payload', {})
                
                search_result = SearchResult(
                    chunk_id=result['id'],
                    file_path=payload.get('file_path', ''),
                    file_name=payload.get('file_name', ''),
                    chunk_name=payload.get('chunk_name', ''),
                    chunk_type=payload.get('chunk_type', ''),
                    language=payload.get('language', ''),
                    start_line=payload.get('start_line', 0),
                    end_line=payload.get('end_line', 0),
                    score=result['score'],
                    content=payload.get('content', ''),
                    metadata=payload
                )
                
                processed.append(search_result)
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ–∏—Å–∫–∞: {e}")
                continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        processed.sort(key=lambda x: x.score, reverse=True)
        
        return processed
    
    def _apply_mmr_ranking(
        self,
        results: List[SearchResult],
        query_vector: np.ndarray,
        top_k: int
    ) -> List[SearchResult]:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç Maximum Marginal Relevance –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
        
        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            query_vector: –í–µ–∫—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            
        Returns:
            –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        if len(results) <= top_k:
            return results
        
        lambda_param = self.config.rag.query_engine.mmr_lambda
        selected = []
        remaining = results.copy()
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π)
        selected.append(remaining.pop(0))
        
        while len(selected) < top_k and remaining:
            best_score = -1
            best_idx = 0
            
            for i, candidate in enumerate(remaining):
                # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –∑–∞–ø—Ä–æ—Å—É
                relevance = candidate.score
                
                # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏
                max_similarity = 0
                for selected_result in selected:
                    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–µ—Ä–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞
                    similarity = self._text_similarity(candidate.content, selected_result.content)
                    max_similarity = max(max_similarity, similarity)
                
                # MMR —Å–∫–æ—Ä
                mmr_score = lambda_param * relevance - (1 - lambda_param) * max_similarity
                
                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = i
            
            selected.append(remaining.pop(best_idx))
        
        return selected
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ—Å—Ç—É—é —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _generate_cache_key(
        self,
        query: str,
        top_k: int,
        language_filter: Optional[str],
        chunk_type_filter: Optional[str],
        min_score: Optional[float],
        file_path_filter: Optional[str]
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞"""
        import hashlib
        
        key_parts = [
            query,
            str(top_k),
            language_filter or '',
            chunk_type_filter or '',
            str(min_score) if min_score is not None else '',
            file_path_filter or ''
        ]
        
        key_string = '|'.join(key_parts)
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[List[SearchResult]]:
        """Thread-safe –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –∫—ç—à–∞"""
        with self._cache_lock:
            if cache_key not in self._query_cache:
                return None
            
            cached_data = self._query_cache[cache_key]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            if time.time() - cached_data['timestamp'] > self._cache_ttl:
                self._query_cache.pop(cache_key, None)  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
                return None
            
            return cached_data['results']
    
    def _update_stats_safely(self, **kwargs) -> None:
        """Thread-safe –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞"""
        with self._stats_lock:
            if 'cache_hits_incr' in kwargs:
                self.stats['cache_hits'] += kwargs['cache_hits_incr']
            if 'cache_misses_incr' in kwargs:
                self.stats['cache_misses'] += kwargs['cache_misses_incr']
            if 'total_queries_incr' in kwargs:
                self.stats['total_queries'] += kwargs['total_queries_incr']
            if 'total_search_time_incr' in kwargs:
                self.stats['total_search_time'] += kwargs['total_search_time_incr']
            if 'last_query_time' in kwargs:
                self.stats['last_query_time'] = kwargs['last_query_time']
            
            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º average results per query
            if self.stats['total_queries'] > 0:
                with self._cache_lock:  # –ë–ª–æ–∫–∏—Ä—É–µ–º –∫—ç—à –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
                    try:
                        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
                        cache_values = list(self._query_cache.values())
                        total_results = sum(len(data.get('results', [])) for data in cache_values)
                        self.stats['avg_results_per_query'] = total_results / self.stats['total_queries']
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ avg_results_per_query: {e}")
                        self.stats['avg_results_per_query'] = 0.0

    def _save_to_cache(self, cache_key: str, results: List[SearchResult]) -> None:
        """Thread-safe —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫—ç—à"""
        with self._cache_lock:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            if len(self._query_cache) >= self._cache_max_size:
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç
                try:
                    if self._query_cache:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫—ç—à –Ω–µ –ø—É—Å—Ç–æ–π
                        oldest_key = min(
                            self._query_cache.keys(), 
                            key=lambda k: self._query_cache[k]['timestamp']
                        )
                        self._query_cache.pop(oldest_key, None)
                except (ValueError, KeyError) as e:
                    # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –æ—á–∏—â–∞–µ–º –æ–¥–∏–Ω –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}, –æ—á–∏—â–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç")
                    if self._query_cache:
                        first_key = next(iter(self._query_cache))
                        self._query_cache.pop(first_key, None)
            
            # –ê—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–ø–∏—Å—å –≤ –∫—ç—à
            self._query_cache[cache_key] = {
                'results': results,
                'timestamp': time.time()
            }
    
    def format_search_results(
        self, 
        results: List[SearchResult], 
        show_content: bool = True,
        max_content_lines: int = 10
    ) -> None:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é Rich.
        
        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            show_content: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —á–∞–Ω–∫–æ–≤
            max_content_lines: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        """
        # –í silent —Ä–µ–∂–∏–º–µ –Ω–µ –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å
        if self.silent_mode or not self.console:
            return
            
        if not results:
            self.console.print("[yellow]üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã[/yellow]")
            return
        
        self.console.print(f"[bold green]üéØ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}[/bold green]")
        self.console.print()
        
        for i, result in enumerate(results, 1):
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            score_color = "green" if result.score > 0.8 else "yellow" if result.score > 0.6 else "red"
            
            header = (
                f"[bold]{i}. {result.chunk_name}[/bold] "
                f"[dim]({result.file_path}:{result.start_line}-{result.end_line})[/dim] "
                f"[{score_color}]score: {result.score:.3f}[/{score_color}]"
            )
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = (
                f"[dim]–Ø–∑—ã–∫: {result.language.title()}, "
                f"–¢–∏–ø: {result.chunk_type}, "
                f"–§–∞–π–ª: {result.file_name}[/dim]"
            )
            
            self.console.print(header)
            self.console.print(metadata)
            
            # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ
            if show_content and result.content:
                content_lines = result.content.split('\n')
                if len(content_lines) > max_content_lines:
                    content = '\n'.join(content_lines[:max_content_lines]) + '\n... (–æ–±—Ä–µ–∑–∞–Ω–æ)'
                else:
                    content = result.content
                
                # –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –ø–æ–¥—Å–≤–µ—Ç–∫–∞
                try:
                    syntax = Syntax(
                        content,
                        result.language,
                        theme="monokai",
                        line_numbers=True,
                        start_line=result.start_line
                    )
                    
                    panel = Panel(
                        syntax,
                        title=f"[bold]{result.chunk_name}[/bold]",
                        border_style="blue"
                    )
                    
                    self.console.print(panel)
                    
                except Exception:
                    # Fallback –±–µ–∑ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–æ–π –ø–æ–¥—Å–≤–µ—Ç–∫–∏
                    self.console.print(Panel(content, border_style="dim"))
            
            self.console.print()
    
    def get_search_stats(self) -> Dict[str, Any]:
        """
        Thread-safe –≤–æ–∑–≤—Ä–∞—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        with self._stats_lock:
            stats = self.stats.copy()
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if stats['total_queries'] > 0:
                stats['avg_search_time'] = stats['total_search_time'] / stats['total_queries']
                stats['cache_hit_rate'] = stats['cache_hits'] / stats['total_queries']
            else:
                stats['avg_search_time'] = 0.0
                stats['cache_hit_rate'] = 0.0
        
        with self._cache_lock:
            stats['cache_size'] = len(self._query_cache)
            stats['cache_max_size'] = self._cache_max_size
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        stats['score_threshold'] = self.config.rag.query_engine.score_threshold
        
        return stats
    
    def clear_cache(self) -> int:
        """
        Thread-safe –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        with self._cache_lock:
            cache_size = len(self._query_cache)
            self._query_cache.clear()
            logger.info(f"–û—á–∏—â–µ–Ω –∫—ç—à –ø–æ–∏—Å–∫–∞: {cache_size} –∑–∞–ø–∏—Å–µ–π")
            return cache_size
    
    def reset_stats(self) -> None:
        """Thread-safe —Å–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞"""
        with self._stats_lock:
            self.stats = {
                'total_queries': 0,
                'cache_hits': 0,
                'cache_misses': 0,
                'total_search_time': 0.0,
                'avg_results_per_query': 0.0,
                'last_query_time': None
            }
            logger.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–±—Ä–æ—à–µ–Ω–∞")
    
    async def close(self) -> None:
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        try:
            await self.vector_store.close()
            self.clear_cache()
            logger.info("SearchService –∑–∞–∫—Ä—ã—Ç")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è SearchService: {e}")
