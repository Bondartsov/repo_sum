"""
–°–µ—Ä–≤–∏—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã.

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã FileScanner, CodeChunker, CPUEmbedder –∏ QdrantVectorStore
–¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
"""

import asyncio
import logging
import time
import uuid
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime

from rich.progress import Progress, TaskID, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn
from rich.console import Console

from config import Config
from file_scanner import FileScanner
from code_chunker import CodeChunker
from parsers.base_parser import ParserRegistry
from utils import FileInfo, ParsedFile, CodeChunk
from .embedder import CPUEmbedder
from .vector_store import QdrantVectorStore
from .exceptions import VectorStoreException, VectorStoreConnectionError

logger = logging.getLogger(__name__)


class IndexerService:
    """
    –°–µ—Ä–≤–∏—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º—É.
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    - –ü–∞—Ä—Å–∏–Ω–≥ –∏ —Ä–∞–∑–±–∏–≤–∫–∞ –∫–æ–¥–∞ –Ω–∞ —á–∞–Ω–∫–∏
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    - –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, config: Config):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        """
        self.config = config
        self.console = Console()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.file_scanner = FileScanner()
        self.parser_registry = ParserRegistry()
        self.code_chunker = CodeChunker()
        self.embedder = CPUEmbedder(config.rag.embeddings, config.rag.parallelism)
        self.vector_store = QdrantVectorStore(config.rag.vector_store)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'failed_files': 0,
            'total_chunks': 0,
            'indexed_chunks': 0,
            'total_time': 0.0,
            'embedding_time': 0.0,
            'indexing_time': 0.0,
            'errors': []
        }
        
        logger.info("IndexerService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def initialize_vector_store(self, recreate: bool = False) -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
        
        Args:
            recreate: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        try:
            await self.vector_store.initialize_collection(recreate=recreate)
            logger.info("–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≥–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {e}")
            raise VectorStoreConnectionError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É: {e}")
    
    async def index_repository(
        self, 
        repo_path: str, 
        batch_size: int = 512, 
        recreate: bool = False,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
        
        Args:
            repo_path: –ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            recreate: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        """
        start_time = time.time()
        repo_path = Path(repo_path).resolve()
        
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_path}")
        
        try:
            # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            self.console.print("[bold blue]üîó –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...[/bold blue]")
            await self.initialize_vector_store(recreate=recreate)
            
            # 2. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            self.console.print("[bold blue]üìÅ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...[/bold blue]")
            files = list(self.file_scanner.scan_repository(str(repo_path)))
            
            if not files:
                self.console.print("[bold red]‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏![/bold red]")
                return {'success': False, 'error': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏'}
            
            self.stats['total_files'] = len(files)
            self.console.print(f"[green]‚úì –ù–∞–π–¥–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏[/green]")
            
            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            if show_progress:
                chunks = await self._process_files_with_progress(files, repo_path)
            else:
                chunks = await self._process_files_simple(files, repo_path)
            
            if not chunks:
                self.console.print("[bold yellow]‚ö†Ô∏è –ù–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏[/bold yellow]")
                return {'success': False, 'error': '–ù–µ —Å–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏'}
            
            # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
            self.console.print(f"[bold blue]üß© –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∫–æ–¥–∞[/bold blue]")
            indexed_count = await self._index_chunks_batch(chunks, batch_size, show_progress)
            
            # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_time = time.time() - start_time
            self.stats['total_time'] = total_time
            
            result = {
                'success': True,
                'repository_path': str(repo_path),
                'total_files': self.stats['total_files'],
                'processed_files': self.stats['processed_files'],
                'failed_files': self.stats['failed_files'],
                'total_chunks': self.stats['total_chunks'],
                'indexed_chunks': indexed_count,
                'total_time': total_time,
                'processing_rate': self.stats['processed_files'] / total_time if total_time > 0 else 0,
                'indexing_rate': indexed_count / total_time if total_time > 0 else 0
            }
            
            self.console.print(f"[bold green]‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f}s[/bold green]")
            return result
            
        except KeyboardInterrupt:
            logger.info("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            self.console.print("[yellow]‚èπÔ∏è –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º[/yellow]")
            raise
            
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            self.console.print(f"[bold red]‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}[/bold red]")
            raise
    
    async def _process_files_with_progress(
        self, 
        files: List[FileInfo], 
        repo_path: Path
    ) -> List[Tuple[CodeChunk, Dict[str, Any]]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        all_chunks = []
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=self.console
        ) as progress:
            
            task = progress.add_task("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤...", total=len(files))
            
            for file_info in files:
                try:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                    progress.update(
                        task, 
                        description=f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {file_info.name}"
                    )
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
                    file_chunks = await self._process_single_file(file_info, repo_path)
                    all_chunks.extend(file_chunks)
                    
                    self.stats['processed_files'] += 1
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_info.path}: {e}")
                    self.stats['failed_files'] += 1
                    self.stats['errors'].append({
                        'file': file_info.path,
                        'error': str(e),
                        'timestamp': datetime.utcnow().isoformat()
                    })
                
                progress.advance(task)
        
        self.stats['total_chunks'] = len(all_chunks)
        return all_chunks
    
    async def _process_files_simple(
        self, 
        files: List[FileInfo], 
        repo_path: Path
    ) -> List[Tuple[CodeChunk, Dict[str, Any]]]:
        """–ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞"""
        all_chunks = []
        
        for i, file_info in enumerate(files, 1):
            try:
                self.console.print(f"[dim]–û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(files)}: {file_info.name}[/dim]")
                
                file_chunks = await self._process_single_file(file_info, repo_path)
                all_chunks.extend(file_chunks)
                
                self.stats['processed_files'] += 1
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_info.path}: {e}")
                self.stats['failed_files'] += 1
                self.stats['errors'].append({
                    'file': file_info.path,
                    'error': str(e),
                    'timestamp': datetime.utcnow().isoformat()
                })
        
        self.stats['total_chunks'] = len(all_chunks)
        return all_chunks
    
    async def _process_single_file(
        self, 
        file_info: FileInfo, 
        repo_path: Path
    ) -> List[Tuple[CodeChunk, Dict[str, Any]]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª: –ø–∞—Ä—Å–∏–Ω–≥ -> —á–∞–Ω–∫–∏–Ω–≥ -> –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
        
        Args:
            file_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
            repo_path: –ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Ñ–∞–π–ª–∞
            parser = self.parser_registry.get_parser(file_info.path)
            if not parser:
                logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª –±–µ–∑ –ø–∞—Ä—Å–µ—Ä–∞: {file_info.path}")
                return []
            
            # 2. –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
            parsed_file = parser.safe_parse(file_info)
            
            # 3. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
            chunks = self.code_chunker.chunk_parsed_file(parsed_file)
            
            if not chunks:
                logger.debug(f"–ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∞–π–ª–∞: {file_info.path}")
                return []
            
            # 4. –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
            result_chunks = []
            relative_path = Path(file_info.path).relative_to(repo_path)
            
            for chunk in chunks:
                metadata = {
                    'file_path': str(relative_path),
                    'file_name': file_info.name,
                    'language': file_info.language,
                    'chunk_name': chunk.name,
                    'chunk_type': chunk.chunk_type,
                    'start_line': chunk.start_line,
                    'end_line': chunk.end_line,
                    'tokens_estimate': chunk.tokens_estimate,
                    'file_size': file_info.size,
                    'indexed_at': datetime.utcnow().isoformat(),
                    'repository': repo_path.name
                }
                
                result_chunks.append((chunk, metadata))
            
            logger.debug(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è {file_info.path}")
            return result_chunks
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_info.path}: {e}")
            raise
    
    async def _index_chunks_batch(
        self, 
        chunks: List[Tuple[CodeChunk, Dict[str, Any]]], 
        batch_size: int,
        show_progress: bool = True
    ) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —á–∞–Ω–∫–∏ –±–∞—Ç—á–∞–º–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        
        Args:
            chunks: –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        """
        if not chunks:
            return 0
        
        start_time = time.time()
        indexed_count = 0
        
        if show_progress:
            progress = Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                TimeElapsedColumn(),
                console=self.console
            )
            progress.start()
            task = progress.add_task("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —á–∞–Ω–∫–æ–≤...", total=len(chunks))
        else:
            progress = None
            task = None
        
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            for i in range(0, len(chunks), batch_size):
                batch = chunks[i:i + batch_size]
                
                if progress:
                    progress.update(task, description=f"–ë–∞—Ç—á {i//batch_size + 1}")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞ —Å –∑–∞–¥–∞—á–µ–π retrieval.passage (Jina v3)
                texts = [chunk.content for chunk, _ in batch]
                
                embed_start = time.time()
                passage_task = getattr(self.config.rag.embeddings, 'task_passage', 'retrieval.passage')
                embeddings = self.embedder.embed_texts(texts, task=passage_task)
                self.stats['embedding_time'] += time.time() - embed_start
                
                if embeddings is None or len(embeddings) == 0:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞ {i//batch_size + 1}")
                    continue
                
                logger.debug(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å task='{passage_task}' –¥–ª—è –±–∞—Ç—á–∞ {i//batch_size + 1}")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –¥–ª—è Qdrant
                points = []
                for j, ((chunk, metadata), embedding) in enumerate(zip(batch, embeddings)):
                    point_id = str(uuid.uuid4())
                    
                    points.append({
                        'id': point_id,
                        'vector': embedding.tolist() if hasattr(embedding, 'tolist') else embedding,
                        'payload': {
                            **metadata,
                            'content': chunk.content,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
                            'point_id': point_id
                        }
                    })
                
                # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤ Qdrant
                index_start = time.time()
                batch_indexed = await self.vector_store.index_documents(points)
                self.stats['indexing_time'] += time.time() - index_start
                
                indexed_count += batch_indexed
                
                if progress:
                    progress.advance(task, len(batch))
                
                # –ö—Ä–∞—Ç–∫–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                await asyncio.sleep(0.1)
        
        finally:
            if progress:
                progress.stop()
        
        total_time = time.time() - start_time
        logger.info(f"–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {indexed_count}/{len(chunks)} —á–∞–Ω–∫–æ–≤ –∑–∞ {total_time:.2f}s")
        
        return indexed_count
    
    async def get_indexing_stats(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        embedder_stats = self.embedder.get_stats()
        vector_store_stats = self.vector_store.get_stats()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        combined_stats = {
            'indexer': self.stats.copy(),
            'embedder': embedder_stats,
            'vector_store': vector_store_stats,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        return combined_stats
    
    async def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
        
        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã
        """
        health_info = {
            'timestamp': datetime.utcnow().isoformat(),
            'status': 'healthy',
            'components': {}
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            vs_health = await self.vector_store.health_check()
            health_info['components']['vector_store'] = vs_health
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–º–±–µ–¥–¥–µ—Ä–∞
            embedder_stats = self.embedder.get_stats()
            health_info['components']['embedder'] = {
                'status': 'healthy' if embedder_stats['is_warmed_up'] else 'warming_up',
                'provider': embedder_stats['provider'],
                'model': embedder_stats['model_name'],
                'stats': embedder_stats
            }
            
            # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
            if vs_health['status'] != 'connected':
                health_info['status'] = 'degraded'
            
        except Exception as e:
            health_info['status'] = 'unhealthy'
            health_info['error'] = str(e)
            logger.error(f"Health check failed: {e}")
        
        return health_info
    
    def reset_stats(self) -> None:
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'failed_files': 0,
            'total_chunks': 0,
            'indexed_chunks': 0,
            'total_time': 0.0,
            'embedding_time': 0.0,
            'indexing_time': 0.0,
            'errors': []
        }
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.embedder.reset_stats()
        self.vector_store.reset_stats()
        
        logger.info("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–±—Ä–æ—à–µ–Ω–∞")
    
    async def close(self) -> None:
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã"""
        try:
            await self.vector_store.close()
            logger.info("IndexerService –∑–∞–∫—Ä—ã—Ç")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è IndexerService: {e}")
