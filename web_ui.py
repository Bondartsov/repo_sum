#!/usr/bin/env python3
"""
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π MD –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
–ó–∞–ø—É—Å–∫: streamlit run web_ui.py
"""

import streamlit as st
import asyncio
import os
from dotenv import load_dotenv
load_dotenv()
import zipfile
import tempfile
import shutil
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import logging
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
from config import get_config, reload_config
from file_scanner import FileScanner
from parsers.base_parser import ParserRegistry
from code_chunker import CodeChunker
from openai_integration import OpenAIManager
from doc_generator import DocumentationGenerator
from utils import (
    setup_logging,
    FileInfo,
    ParsedFile,
    GPTAnalysisRequest,
    GPTAnalysisResult,
    ensure_directory_exists,
    create_error_parsed_file,
    create_error_gpt_result,
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
try:
    from rag import (
        CPUEmbedder,
        QdrantVectorStore,
        CPUQueryEngine,
        IndexerService,
        SearchService,
        RagException,
        VectorStoreException,
        VectorStoreConnectionError
    )
    RAG_AVAILABLE = True
except ImportError as e:
    logger.warning(f"RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
    RAG_AVAILABLE = False
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤
    CPUEmbedder = None
    QdrantVectorStore = None
    CPUQueryEngine = None
    IndexerService = None
    SearchService = None
    RagException = Exception
    VectorStoreException = Exception
    VectorStoreConnectionError = Exception

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
setup_logging("INFO")


def validate_uploaded_file(uploaded_file) -> Tuple[bool, str]:
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å"""
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    ALLOWED_EXTENSIONS = {'.zip'}
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    if uploaded_file.size > MAX_FILE_SIZE:
        return False, f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {uploaded_file.size / (1024*1024):.1f}MB. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILE_SIZE / (1024*1024):.0f}MB"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    file_ext = Path(uploaded_file.name).suffix.lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        return False, f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_ext}. –†–∞–∑—Ä–µ—à–µ–Ω—ã: {', '.join(ALLOWED_EXTENSIONS)}"
    
    return True, "OK"


def safe_extract_zip(zip_path: Path, extract_to: Path) -> Tuple[bool, str, Optional[str]]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç ZIP –∞—Ä—Ö–∏–≤ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –Ω–∞ path traversal"""
    MAX_EXTRACTED_SIZE = 500 * 1024 * 1024  # 500MB
    MAX_FILES = 10000
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∞—Ä—Ö–∏–≤–∞
            file_count = 0
            total_size = 0
            
            for zip_info in zip_ref.infolist():
                file_count += 1
                total_size += zip_info.file_size
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
                if file_count > MAX_FILES:
                    return False, f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –∞—Ä—Ö–∏–≤–µ: {file_count}. –ú–∞–∫—Å–∏–º—É–º: {MAX_FILES}", None
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                if total_size > MAX_EXTRACTED_SIZE:
                    return False, f"–ê—Ä—Ö–∏–≤ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {total_size / (1024*1024):.1f}MB. –ú–∞–∫—Å–∏–º—É–º: {MAX_EXTRACTED_SIZE / (1024*1024):.0f}MB", None
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ path traversal
                if '..' in zip_info.filename or zip_info.filename.startswith('/'):
                    return False, f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã–π –ø—É—Ç—å –≤ –∞—Ä—Ö–∏–≤–µ: {zip_info.filename}", None
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
                if any(dangerous in zip_info.filename.lower() for dangerous in ['.exe', '.bat', '.sh', '.cmd']):
                    logger.warning(f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –≤ –∞—Ä—Ö–∏–≤–µ: {zip_info.filename}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ö–∏–≤
            zip_ref.extractall(extract_to)
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É
            extracted_dirs = [d for d in extract_to.iterdir() if d.is_dir()]
            if extracted_dirs:
                repo_path = str(extracted_dirs[0])
            else:
                repo_path = str(extract_to)
            
            return True, "OK", repo_path
            
    except zipfile.BadZipFile:
        return False, "–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π ZIP –∞—Ä—Ö–∏–≤", None
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}", None


class WebRepositoryAnalyzer:
    """–ê–¥–∞–ø—Ç–µ—Ä –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    
    def __init__(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è API –∫–ª—é—á–∞ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ
        self.config = get_config(require_api_key=False)
        self.file_scanner = FileScanner()
        self.parser_registry = ParserRegistry()
        self.code_chunker = CodeChunker()
        self.openai_manager = None
        self.doc_generator = DocumentationGenerator()
        
    def initialize_with_api_key(self, api_key: str) -> bool:
        logger.debug(f"initialize_with_api_key: api_key length={len(api_key) if api_key else 0}, env_key_set={bool(os.getenv('OPENAI_API_KEY'))}")
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å API –∫–ª—é—á–æ–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ API –∫–ª—é—á –Ω–µ –ø—É—Å—Ç–æ–π
            if not api_key or not api_key.strip():
                logger.error("API –∫–ª—é—á –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω")
                return False
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
            os.environ['OPENAI_API_KEY'] = api_key.strip()
            logger.debug("initialize_with_api_key: API key set in environment")
            
            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            reload_config()
            self.config = get_config()
            
            # –°–æ–∑–¥–∞–µ–º OpenAI manager —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            self.openai_manager = OpenAIManager()
            
            logger.info("OpenAI API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except ValueError as e:
            logger.exception("–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ API –∫–ª—é—á–∞")
            return False
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å API –∫–ª—é—á–æ–º")
            return False
    
    async def analyze_repository(self, repo_path: str, output_path: str, progress_callback=None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –æ–±—Ä–∞—Ç–Ω—ã–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {repo_path}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            ensure_directory_exists(output_path)
            
            # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            if progress_callback:
                progress_callback("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...", 0)
            
            files_to_analyze = list(self.file_scanner.scan_repository(repo_path))
            
            if not files_to_analyze:
                return {'success': False, 'error': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(files_to_analyze)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            analyzed_files = []
            total_files = len(files_to_analyze)
            
            for i, file_info in enumerate(files_to_analyze):
                try:
                    if progress_callback:
                        progress = int((i / total_files) * 100)
                        progress_callback(f"–ê–Ω–∞–ª–∏–∑: {Path(file_info.path).name}", progress)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
                    parsed_file, gpt_result = await self._analyze_single_file(file_info)
                    analyzed_files.append((parsed_file, gpt_result))
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {file_info.path}: {e}")
                    # –ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—à–∏–±–æ–∫
                    analyzed_files.append((
                        create_error_parsed_file(file_info, e),
                        create_error_gpt_result(e)
                    ))
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
            if progress_callback:
                progress_callback("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...", 90)
            
            result = self.doc_generator.generate_complete_documentation(
                analyzed_files, output_path, repo_path
            )
            
            if progress_callback:
                progress_callback("–ó–∞–≤–µ—Ä—à–µ–Ω–æ!", 100)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
            if self.openai_manager:
                token_stats = self.openai_manager.get_token_usage_stats()
                result['token_stats'] = token_stats
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _analyze_single_file(self, file_info: FileInfo):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        parser = self.parser_registry.get_parser(file_info.path)
        if not parser:
            raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Ñ–∞–π–ª–∞ {file_info.path}")
        
        # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
        parsed_file = parser.safe_parse(file_info)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        chunks = self.code_chunker.chunk_parsed_file(parsed_file)
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT
        gpt_request = GPTAnalysisRequest(
            chunks=chunks,
            file_path=file_info.path,
            language=file_info.language
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GPT
        gpt_result = await self.openai_manager.analyze_code(gpt_request)
        
        return parsed_file, gpt_result
    
    def get_repository_stats(self, repo_path: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        return self.file_scanner.get_repository_stats(repo_path)


@st.cache_resource
def get_analyzer():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    return WebRepositoryAnalyzer()


@st.cache_resource
def init_rag_components():
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
    
    Returns:
        Tuple[Optional[SearchService], Optional[CPUQueryEngine], Optional[IndexerService], str]:
            –ö–æ—Ä—Ç–µ–∂ (search_service, query_engine, indexer_service, status_message)
    """
    if not RAG_AVAILABLE:
        return None, None, None, "RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = get_config(require_api_key=False)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        embedder = CPUEmbedder(config.rag.embeddings, config.rag.parallelism)
        vector_store = QdrantVectorStore(config.rag.vector_store)
        search_service = SearchService(config, silent_mode=True)
        query_engine = CPUQueryEngine(embedder, vector_store, config.rag.query_engine)
        indexer_service = IndexerService(config)
        
        logger.info("RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return search_service, query_engine, indexer_service, "RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞"
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
        return None, None, None, f"–û—à–∏–±–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã: {e}"


def get_current_api_key() -> Optional[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π API –∫–ª—é—á –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞.
    
    Returns:
        API –∫–ª—é—á –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º session state (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–ª –≤—Ä—É—á–Ω—É—é)
    if 'manual_api_key' in st.session_state and st.session_state.manual_api_key:
        api_key = st.session_state.manual_api_key.strip()
        if api_key and not api_key.startswith('your_'):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
            return api_key
    
    # 2. –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    env_api_key = os.getenv('OPENAI_API_KEY', '').strip()
    if env_api_key and not env_api_key.startswith('your_'):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
        return env_api_key
    
    return None


def validate_api_key(api_key: str) -> tuple[bool, str]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç API –∫–ª—é—á OpenAI.
    
    Args:
        api_key: API –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (–≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å, —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ)
    """
    if not api_key or not api_key.strip():
        return False, "API –∫–ª—é—á –ø—É—Å—Ç–æ–π"
    
    api_key = api_key.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
    if api_key.startswith('your_') and api_key.endswith('_here'):
        return False, "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤–º–µ—Å—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API –∫–ª—é—á–∞"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç OpenAI API –∫–ª—é—á–∞
    if not api_key.startswith('sk-'):
        return False, "API –∫–ª—é—á –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'sk-'"
    
    if len(api_key) < 20:
        return False, "API –∫–ª—é—á —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π"
    
    return True, "OK"


def run_async(coro):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ Streamlit.
    
    Args:
        coro: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
    """
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)


def format_search_results_for_display(results, max_content_lines=10):
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Streamlit.
    
    Args:
        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        max_content_lines: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    formatted_results = []
    
    for i, result in enumerate(results, 1):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç —Å–∫–æ—Ä–∞
        score_color = "üü¢" if result.score > 0.8 else "üü°" if result.score > 0.6 else "üî¥"
        
        # –û–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        content_lines = result.content.split('\n')
        if len(content_lines) > max_content_lines:
            content = '\n'.join(content_lines[:max_content_lines]) + '\n... (–æ–±—Ä–µ–∑–∞–Ω–æ)'
        else:
            content = result.content
        
        formatted_result = {
            'index': i,
            'title': f"{score_color} {i}. {result.chunk_name}",
            'subtitle': f"{result.file_path}:{result.start_line}-{result.end_line} | –°–∫–æ—Ä: {result.score:.3f}",
            'metadata': f"–Ø–∑—ã–∫: {result.language.title()}, –¢–∏–ø: {result.chunk_type}, –§–∞–π–ª: {result.file_name}",
            'content': content,
            'language': result.language,
            'start_line': result.start_line,
            'original_result': result
        }
        
        formatted_results.append(formatted_result)
    
    return formatted_results


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    
    st.title("üìö –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
    st.markdown("–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π MD –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é OpenAI GPT")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–∞
        st.subheader("üîë OpenAI API")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        existing_api_key = os.getenv('OPENAI_API_KEY', '')
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è API –∫–ª—é—á–∞
        if 'api_key_source' not in st.session_state:
            st.session_state.api_key_source = 'env' if existing_api_key else 'input'
        
        # –ö–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ API –∫–ª—é—á–∞
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÑ –í–∑—è—Ç—å –∏–∑ .env", disabled=not existing_api_key):
                st.session_state.api_key_source = 'env'
        with col2:
            if st.button("‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"):
                st.session_state.api_key_source = 'input'
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        if st.session_state.api_key_source == 'env' and existing_api_key:
            st.success("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env)")
            api_key = existing_api_key
            # –û—á–∏—â–∞–µ–º manual_api_key —á—Ç–æ–±—ã get_current_api_key() –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª env
            st.session_state.manual_api_key = ""
        else:
            api_key = st.text_input(
                "API –∫–ª—é—á",
                value=st.session_state.get('manual_api_key', ''),
                placeholder="sk-...",
                type="password",
                help="–ü–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á –Ω–∞ https://platform.openai.com/api-keys"
            )
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–≤–µ–¥–µ–Ω–Ω—ã–π –∫–ª—é—á –≤ session_state –¥–ª—è get_current_api_key()
            if api_key != st.session_state.get('manual_api_key', ''):
                st.session_state.manual_api_key = api_key
            
            if api_key:
                st.success("‚úÖ API –∫–ª—é—á –≤–≤–µ–¥–µ–Ω")
            elif not existing_api_key:
                st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ OpenAI API –∫–ª—é—á –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env")
            else:
                st.info("‚ÑπÔ∏è –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ '–í–∑—è—Ç—å –∏–∑ .env'")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        st.subheader("üõ†Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        model_choice = st.selectbox(
            "–ú–æ–¥–µ–ª—å GPT",
            ["gpt-4.1-nano", "gpt-4o", "gpt-3.5-turbo"],
            index=0,
            help="gpt-4.1-nano - –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)"
        )
        
        # RAG —Å–∏—Å—Ç–µ–º–∞ —Å—Ç–∞—Ç—É—Å
        st.subheader("üîç RAG –°–∏—Å—Ç–µ–º–∞")
        search_service, query_engine, indexer_service, rag_status = init_rag_components()
        
        if search_service is not None:
            st.success(f"‚úÖ {rag_status}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ Jina v3 –º–æ–¥–µ–ª–∏
            try:
                config = get_config(require_api_key=False)
                model_name = config.rag.embeddings.model_name
                vector_size = config.rag.embeddings.truncate_dim
                
                if "jinaai/jina-embeddings-v3" in model_name:
                    st.info(f"üöÄ **Jina v3 Architecture**: {model_name} ({vector_size}d –≤–µ–∫—Ç–æ—Ä—ã, dual task)")
                else:
                    st.info(f"üìä **Embedding Model**: {model_name} ({vector_size}d –≤–µ–∫—Ç–æ—Ä—ã)")
            except:
                st.info("üìä **RAG Model**: –ê–∫—Ç–∏–≤–Ω–∞")
            
            if st.button("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG"):
                try:
                    stats = search_service.get_search_stats()  # –£–±–∏—Ä–∞–µ–º run_async –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
                    with st.expander("üìà –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", expanded=True):
                        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∏—Å–∫–∞
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", stats.get('total_queries', 0))
                            st.metric("–ü–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à", stats.get('cache_hits', 0))
                        with col2:
                            st.metric("–†–∞–∑–º–µ—Ä –∫—ç—à–∞", stats.get('cache_size', 0))
                            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞", f"{stats.get('avg_search_time', 0):.3f}s")
                            
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        col3, col4 = st.columns(2)
                        with col3:
                            st.metric("–ü—Ä–æ–º–∞—Ö–∏ –∫—ç—à–∞", stats.get('cache_misses', 0))
                            st.metric("–ö–æ—ç—Ñ. –ø–æ–ø–∞–¥–∞–Ω–∏—è", f"{stats.get('cache_hit_rate', 0):.1%}")
                        with col4:
                            if stats.get('last_query_time'):
                                st.caption(f"–ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å: {stats['last_query_time'][:19].replace('T', ' ')}")
                            st.metric("–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞", stats.get('cache_max_size', 0))
                        
                        st.divider()
                        
                        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è Jina v3)
                        try:
                            config = get_config(require_api_key=False)
                            if "jinaai/jina-embeddings-v3" in config.rag.embeddings.model_name:
                                st.markdown("**üîß Jina v3 Technical Specs:**")
                                
                                tech_col1, tech_col2, tech_col3 = st.columns(3)
                                with tech_col1:
                                    st.metric("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏", "570M")
                                    st.metric("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å", f"{config.rag.embeddings.truncate_dim}d")
                                with tech_col2:
                                    st.metric("Task Query", config.rag.embeddings.task_query)
                                    st.metric("Task Passage", config.rag.embeddings.task_passage)
                                with tech_col3:
                                    st.metric("Trust Remote Code", "‚úÖ" if config.rag.embeddings.trust_remote_code else "‚ùå")
                                    st.metric("L2 Normalize", "‚úÖ" if config.rag.embeddings.get('normalize_embeddings', True) else "‚ùå")
                        except:
                            pass  # Ignore config errors in sidebar
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        else:
            st.error(f"‚ùå {rag_status}")
            st.info("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Qdrant –¥–ª—è RAG —Ñ—É–Ω–∫—Ü–∏–π")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    analyzer = get_analyzer()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
    if 'analysis_completed' not in st.session_state:
        st.session_state.analysis_completed = False
    if 'analysis_result' not in st.session_state:
        st.session_state.analysis_result = None
    
    # –í–∫–ª–∞–¥–∫–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    tab1, tab2, tab3, tab4 = st.tabs(["üìÅ –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è", "üîç RAG: –ü–æ–∏—Å–∫", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "‚ùì –°–ø—Ä–∞–≤–∫–∞"])
    
    with tab1:
        st.header("üìÅ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –í—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ –∑–∞–≥—Ä—É–∑–∫–∏
        upload_method = st.radio(
            "–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:",
            ["–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ", "ZIP –∞—Ä—Ö–∏–≤"],
            horizontal=True
        )
        
        repo_path = None
        temp_dir = None
        
        if upload_method == "–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ":
            repo_path = st.text_input(
                "–ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é",
                placeholder="C:/path/to/your/repository",
                help="–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º"
            )
            
            if repo_path and Path(repo_path).exists():
                st.success(f"‚úÖ –ü–∞–ø–∫–∞ –Ω–∞–π–¥–µ–Ω–∞: {repo_path}")
            elif repo_path:
                st.error("‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                repo_path = None
        
        else:  # ZIP –∞—Ä—Ö–∏–≤
            uploaded_file = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º",
                type=['zip'],
                help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥"
            )
            
            if uploaded_file is not None:
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                is_valid, error_msg = validate_uploaded_file(uploaded_file)
                if not is_valid:
                    st.error(f"‚ùå {error_msg}")
                    repo_path = None
                else:
                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    temp_dir = tempfile.mkdtemp()
                    zip_path = Path(temp_dir) / uploaded_file.name
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    with open(zip_path, 'wb') as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ö–∏–≤
                    success, message, extracted_path = safe_extract_zip(zip_path, Path(temp_dir))
                    
                    if success:
                        repo_path = extracted_path
                        st.success(f"‚úÖ –ê—Ä—Ö–∏–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω: {uploaded_file.name}")
                    else:
                        st.error(f"‚ùå {message}")
                        repo_path = None
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if repo_path:
            st.subheader("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–∞—Ö")
            
            try:
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                scanner = FileScanner()
                total_files = scanner.count_files(repo_path)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("–§–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", total_files)
                with col2:
                    st.metric("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤", len(scanner.supported_extensions))
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–∫–ª—é—á–µ–Ω–∏—è—Ö
                with st.expander("‚ÑπÔ∏è –ö–∞–∫–∏–µ —Ñ–∞–π–ª—ã –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"):
                    st.markdown("""
                    **üóÇÔ∏è –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:**
                    - **–°–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Ä—Å–∏–π**: `.git`, `.svn`, `.hg` - —Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    - **–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**: `node_modules`, `venv`, `.venv` - —Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –∫–æ–¥
                    - **–ö—ç—à–∏**: `__pycache__`, `.pytest_cache` - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                    - **–°–±–æ—Ä–∫–∞**: `target`, `build`, `dist` - –∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥  
                    - **IDE**: `.idea`, `.vscode` - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä–æ–≤
                    - **–õ–æ–≥–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ**: `logs`, `tmp`, `temp` - —Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    
                    **üî∏ –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã:**
                    - –°–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å —Ç–æ—á–∫–∏)
                    - –§–∞–π–ª—ã –±–æ–ª—å—à–µ 10MB (–∑–∞—â–∏—Ç–∞ –æ—Ç –±–æ–ª—å—à–∏—Ö –±–∏–Ω–∞—Ä–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤)
                    - –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
                    
                    **üí° –†–µ–∑—É–ª—å—Ç–∞—Ç:** –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–∞—à –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã
                    """)
                    
                # –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
                if total_files > 100:
                    st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤. –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤ OpenAI.")
                    
                    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                    estimated_tokens = total_files * 800  # –ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                    estimated_cost = estimated_tokens * 0.000001  # —Ü–µ–Ω–∞ –∑–∞ —Ç–æ–∫–µ–Ω –¥–ª—è gpt-4.1-nano
                    st.info(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: {estimated_tokens:,} —Ç–æ–∫–µ–Ω–æ–≤ (~${estimated_cost:.3f})")
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ñ–∞–π–ª–æ–≤: {e}")
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–æ–≤
        if repo_path:
            with st.expander("üëÄ –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"):
                try:
                    stats = analyzer.get_repository_stats(repo_path)
                    
                    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤", stats['total_files'])
                    with col2:
                        st.metric("–†–∞–∑–º–µ—Ä", f"{stats['total_size'] / 1024 / 1024:.1f} MB")
                    with col3:
                        st.metric("–Ø–∑—ã–∫–æ–≤", len(stats['languages']))
                    with col4:
                        if stats['total_files'] > 0:
                            avg_size = stats['total_size'] / stats['total_files'] / 1024
                            st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞", f"{avg_size:.1f} KB")
                        else:
                            st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞", "0 KB")
                    
                    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —è–∑—ã–∫–∞–º —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏
                    if stats['languages']:
                        st.write("**üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è:**")
                        
                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ñ–∞–π–ª–æ–≤
                        sorted_languages = sorted(stats['languages'].items(), key=lambda x: x[1], reverse=True)
                        
                        for lang, count in sorted_languages:
                            percentage = (count / stats['total_files']) * 100
                            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                            progress_bar_html = f"""
                            <div style="background-color: #f0f2f6; border-radius: 10px; overflow: hidden; margin: 2px 0;">
                                <div style="background-color: #1f77b4; height: 20px; width: {percentage:.1f}%; 
                                           display: flex; align-items: center; padding-left: 8px; color: white; font-size: 12px;">
                                    <strong>{lang.title()}</strong>: {count} —Ñ–∞–π–ª–æ–≤ ({percentage:.1f}%)
                                </div>
                            </div>
                            """
                            st.markdown(progress_bar_html, unsafe_allow_html=True)
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–¥–∏—Ä–æ–≤–∫–∞—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ)
                    if len(stats.get('encoding_distribution', {})) > 1:
                        st.write("**üî§ –ö–æ–¥–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤:**")
                        for encoding, count in stats['encoding_distribution'].items():
                            st.write(f"‚Ä¢ {encoding}: {count} —Ñ–∞–π–ª–æ–≤")
                    
                    # –¢–æ–ø —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    if stats.get('largest_files'):
                        st.write("**üìà –°–∞–º—ã–µ –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã:**")
                        for i, file_info in enumerate(stats['largest_files'][:5], 1):
                            size_mb = file_info['size'] / 1024 / 1024
                            file_path = Path(file_info['path']).name  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞
                            st.write(f"{i}. **{file_path}** ({file_info['language'].title()}) - {size_mb:.2f} MB")
                
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞–ø–∫–∏: {e}")
        
        # RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        if search_service and indexer_service:
            enable_rag_indexing = st.checkbox(
                "üìä –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤ RAG —Å–∏—Å—Ç–µ–º—É",
                value=True,
                help="–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"
            )
        else:
            enable_rag_indexing = False
            if repo_path:
                st.info("‚ÑπÔ∏è RAG —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
        if st.button("üöÄ –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", disabled=not (repo_path and api_key)):
            if not api_key:
                st.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–≤–µ—Å—Ç–∏ OpenAI API –∫–ª—é—á")
            elif not repo_path:
                st.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π")
            else:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å API –∫–ª—é—á–æ–º
                if not analyzer.initialize_with_api_key(api_key):
                    st.error("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å API –∫–ª—é—á–æ–º")
                else:
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø–µ—Ä–µ–¥–∞–µ–º repo_path –Ω–∞–ø—Ä—è–º—É—é, –∞ –Ω–µ —Å–æ–∑–¥–∞–µ–º web_output
                    # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –≤ –∫–æ—Ä–Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def update_progress(message: str, progress: int):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    try:
                        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –ø–µ—Ä–µ–¥–∞–µ–º repo_path –∫–∞–∫ output_dir
                        result = asyncio.run(analyzer.analyze_repository(
                            repo_path,
                            repo_path,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º repo_path –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è SUMMARY_REPORT_ –≤–Ω—É—Ç—Ä–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
                            progress_callback=update_progress
                        ))
                        
                        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
                        if enable_rag_indexing and indexer_service:
                            try:
                                status_text.text("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ RAG —Å–∏—Å—Ç–µ–º—É...")
                                progress_bar.progress(95)
                                
                                # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
                                indexing_result = run_async(indexer_service.index_repository(
                                    repo_path,
                                    batch_size=512,
                                    recreate=False,
                                    show_progress=False
                                ))
                                
                                if indexing_result and indexing_result.get('success', False):
                                    st.success(f"üéØ RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {indexing_result.get('indexed_chunks', 0)} —á–∞–Ω–∫–æ–≤")
                                    result['rag_indexing'] = indexing_result
                                else:
                                    st.warning("‚ö†Ô∏è RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
                                    result['rag_indexing'] = {'success': False, 'error': '–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å'}
                                    
                            except Exception as rag_error:
                                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {rag_error}")
                                logger.exception("–û—à–∏–±–∫–∞ RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
                                result['rag_indexing'] = {'success': False, 'error': str(rag_error)}
                        
                        st.session_state.analysis_result = result
                        st.session_state.analysis_completed = True
                        
                        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞
                        if temp_dir and Path(temp_dir).exists():
                            shutil.rmtree(temp_dir)
                        
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
                        if temp_dir and Path(temp_dir).exists():
                            shutil.rmtree(temp_dir)
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if st.session_state.analysis_completed and st.session_state.analysis_result:
            result = st.session_state.analysis_result
            
            if result.get('success', True):
                st.success("üéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                
                # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.subheader("üìà –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤", result.get('scanned_files', result.get('total_files', 0)))
                with col2:
                    st.metric("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", result.get('successful', 0))
                with col3:
                    st.metric("–° –æ—à–∏–±–∫–∞–º–∏", result.get('failed', 0))
                with col4:
                    success_rate = 0
                    total = result.get('total_files', 0)
                    if total > 0:
                        success_rate = (result.get('successful', 0) / total) * 100
                    st.metric("–£—Å–ø–µ—à–Ω–æ—Å—Ç—å", f"{success_rate:.1f}%")
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∞—Ö –∏ –∑–∞—Ç—Ä–∞—Ç–∞—Ö
                if 'token_stats' in result:
                    token_stats = result['token_stats']
                    used_tokens = token_stats.get('used_today', 0)
                    estimated_cost = used_tokens * 0.000001  # –ø—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è gpt-4.1-nano
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"üî¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {used_tokens:,}")
                    with col2:
                        st.info(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${estimated_cost:.4f}")
                
                # –°—Ç–∞—Ç—É—Å RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                if 'rag_indexing' in result:
                    st.subheader("üîç –°—Ç–∞—Ç—É—Å RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
                    rag_result = result['rag_indexing']
                    
                    if rag_result.get('success', False):
                        st.success("‚úÖ RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                        
                        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤", rag_result.get('indexed_chunks', 0))
                        with col2:
                            st.metric("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤", rag_result.get('processed_files', 0))
                        with col3:
                            processing_time = rag_result.get('processing_time', 0)
                            st.metric("–í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", f"{processing_time:.1f}s")
                        
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ RAG
                        if rag_result.get('indexed_chunks', 0) > 0:
                            st.info("üí° –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É –≤–æ –≤–∫–ª–∞–¥–∫–µ 'RAG: –ü–æ–∏—Å–∫'")
                    else:
                        st.warning(f"‚ö†Ô∏è RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π: {rag_result.get('error', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                        st.info("‚ÑπÔ∏è –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ, –Ω–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–µ —Å–æ–∑–¥–∞–Ω. –í—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å –µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ –≤–æ –≤–∫–ª–∞–¥–∫–µ 'RAG: –ü–æ–∏—Å–∫'")
                
                # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                output_path = result.get('output_directory', './web_output')
                if Path(output_path).exists():
                    st.success(f"üìÅ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: `{output_path}`")
                    
                    # –°–æ–∑–¥–∞–µ–º ZIP –∞—Ä—Ö–∏–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                    zip_path = Path(output_path).parent / "documentation.zip"
                    try:
                        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                            for file_path in Path(output_path).rglob('*'):
                                if file_path.is_file():
                                    arcname = file_path.relative_to(output_path)
                                    zipf.write(file_path, arcname)
                        
                        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                        with open(zip_path, 'rb') as f:
                            st.download_button(
                                label="üì• –°–∫–∞—á–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é (ZIP)",
                                data=f.read(),
                                file_name="documentation.zip",
                                mime="application/zip"
                            )
                    
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å ZIP –∞—Ä—Ö–∏–≤: {e}")
                
                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                if st.button("üîÑ –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"):
                    st.session_state.analysis_completed = False
                    st.session_state.analysis_result = None
                    st.rerun()
            
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
    
    with tab2:
        st.header("üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        search_service, query_engine, indexer_service, rag_status = init_rag_components()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å RAG —Å–∏—Å—Ç–µ–º—ã
        if search_service is not None:
            st.success(f"‚úÖ {rag_status}")
        else:
            st.error(f"‚ùå {rag_status}")
            st.info("üí° –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Ñ—É–Ω–∫—Ü–∏–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Qdrant –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RAG —Å–∏—Å—Ç–µ–º—É")
        
        # –ù–û–í–û–ï: Standalone RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        st.subheader("üìö –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è")
        st.markdown("*–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç OpenAI API)*")
        
        # –í—ã–±–æ—Ä —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        col1, col2 = st.columns([3, 1])
        with col1:
            index_repo_path = st.text_input(
                "–ü—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
                placeholder="C:/path/to/your/repository",
                help="–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"
            )
        with col2:
            recreate_index = st.checkbox(
                "–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å",
                value=False,
                help="–£–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å –∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π"
            )
        
        # –ö–Ω–æ–ø–∫–∞ standalone –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        if st.button(
            "üîÑ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", 
            type="secondary", 
            disabled=not (indexer_service and index_repo_path and Path(index_repo_path).exists())
        ):
            if not indexer_service:
                st.error("‚ùå RAG —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            elif not index_repo_path:
                st.warning("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é")
            elif not Path(index_repo_path).exists():
                st.error("‚ùå –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                try:
                    with st.spinner("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –≤ RAG —Å–∏—Å—Ç–µ–º—É..."):
                        indexing_result = run_async(indexer_service.index_repository(
                            index_repo_path,
                            batch_size=512,
                            recreate=recreate_index,
                            show_progress=False
                        ))
                        
                        if indexing_result and indexing_result.get('success', False):
                            st.success(f"üéØ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                            
                            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —á–∞–Ω–∫–æ–≤", indexing_result.get('indexed_chunks', 0))
                            with col2:
                                st.metric("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤", indexing_result.get('processed_files', 0))
                            with col3:
                                st.metric("–í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏", f"{indexing_result.get('processing_time', 0):.1f}s")
                                
                            st.info("üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —ç—Ç–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é")
                            
                        else:
                            error_msg = indexing_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞') if indexing_result else '–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å'
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {error_msg}")
                            
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
                    logger.exception("–û—à–∏–±–∫–∞ standalone RAG –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        
        st.divider()
        
        # –†–∞–∑–¥–µ–ª—ã RAG –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        rag_mode = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:",
            ["üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫", "üí¨ Q&A –ø–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é"],
            horizontal=True
        )
        
        if rag_mode == "üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫":
            st.subheader("üîç –ü–æ–∏—Å–∫ –ø–æ –∫–æ–¥—É")
            
            # –ü–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
            query = st.text_input(
                "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–¥—É",
                placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: authentication middleware, database connection, error handling"
            )
            
            col1, col2, col3 = st.columns(3)
            with col1:
                top_k = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", 1, 20, 10)
            with col2:
                lang_filter = st.selectbox(
                    "–Ø–∑—ã–∫",
                    ["–≤—Å–µ", "python", "javascript", "typescript", "cpp", "csharp", "java", "go", "rust"]
                )
            with col3:
                chunk_type = st.selectbox(
                    "–¢–∏–ø",
                    ["–≤—Å–µ", "function", "class", "imports", "other"]
                )
            
            # –ö–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
            if st.button("üîç –ü–æ–∏—Å–∫", type="primary", disabled=not search_service or not query.strip()):
                if not query.strip():
                    st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
                elif not search_service:
                    st.error("‚ùå RAG —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                else:
                    try:
                        with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞..."):
                            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞
                            language_filter = None if lang_filter == "–≤—Å–µ" else lang_filter
                            chunk_type_filter = None if chunk_type == "–≤—Å–µ" else chunk_type
                            
                            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞
                            results = run_async(search_service.search(
                                query=query,
                                top_k=top_k,
                                language_filter=language_filter,
                                chunk_type_filter=chunk_type_filter,
                                min_score=0.5
                            ))
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            if results:
                                st.success(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                                
                                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                formatted_results = format_search_results_for_display(results)
                                
                                for result in formatted_results:
                                    with st.expander(f"{result['title']} - {result['subtitle']}", expanded=False):
                                        st.caption(result['metadata'])
                                        
                                        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–¥–∞ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
                                        st.code(
                                            result['content'],
                                            language=result['language'],
                                            line_numbers=True
                                        )
                                        
                                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                                        st.caption(f"üìç –°—Ç—Ä–æ–∫–∏: {result['start_line']}-{result['original_result'].end_line}")
                            else:
                                st.info("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞.")
                                
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
                        logger.exception("–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞")
        
        elif rag_mode == "üí¨ Q&A –ø–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é":
            st.subheader("üí¨ Q&A –ø–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
            if "rag_chat_history" not in st.session_state:
                st.session_state.rag_chat_history = []
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
            for i, (question, answer, context_files) in enumerate(st.session_state.rag_chat_history):
                with st.container():
                    st.markdown(f"**‚ùì –í–æ–ø—Ä–æ—Å {i+1}:** {question}")
                    st.markdown(f"**üí° –û—Ç–≤–µ—Ç:** {answer}")
                    if context_files:
                        st.caption(f"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {', '.join(context_files)}")
                    st.divider()
            
            # –ü–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–æ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            question = st.text_area(
                "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –∫–æ–¥–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è",
                placeholder="–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ?\n–ö–∞–∫–∏–µ –µ—Å—Ç—å API endpoints?\n–ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö?",
                height=100
            )
            
            col1, col2 = st.columns([1, 4])
            with col1:
                context_limit = st.number_input("–ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ñ–∞–π–ª—ã)", 1, 10, 5)
            
            # –ö–Ω–æ–ø–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–æ–ø—Ä–æ—Å–∞
            if st.button("üí¨ –û—Ç–≤–µ—Ç–∏—Ç—å", type="primary", disabled=not search_service or not query_engine or not question.strip()):
                # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π API –∫–ª—é—á
                current_api_key = get_current_api_key()
                
                if not question.strip():
                    st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
                elif not search_service or not query_engine:
                    st.error("‚ùå RAG —Å–∏—Å—Ç–µ–º–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                elif not current_api_key:
                    st.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º OpenAI API –∫–ª—é—á –¥–ª—è Q&A")
                else:
                    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º API –∫–ª—é—á
                    is_valid, error_msg = validate_api_key(current_api_key)
                    if not is_valid:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ API –∫–ª—é—á–∞: {error_msg}")
                        return
                    try:
                        with st.spinner("–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
                            # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∞ —Å retry –ª–æ–≥–∏–∫–æ–π
                            search_results = None
                            max_retries = 2
                            
                            for attempt in range(max_retries):
                                try:
                                    search_results = run_async(search_service.search(
                                        query=question,
                                        top_k=context_limit,
                                        min_score=0.6
                                    ))
                                    break  # –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                                except Exception as search_error:
                                    logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–∏—Å–∫–∞ {attempt + 1}/{max_retries} –Ω–µ—É–¥–∞—á–Ω–∞: {search_error}")
                                    if attempt == max_retries - 1:
                                        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω–∞, –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                                        raise search_error
                                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                                    import time
                                    time.sleep(0.5)
                            
                            if search_results:
                                # 2. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
                                context_parts = []
                                context_files = []
                                
                                for result in search_results:
                                    context_parts.append(f"""
**–§–∞–π–ª:** {result.file_path} (—Å—Ç—Ä–æ–∫–∏ {result.start_line}-{result.end_line})
**–¢–∏–ø:** {result.chunk_type}
**–ö–æ–¥:**
```{result.language}
{result.content}
```
""")
                                    if result.file_name not in context_files:
                                        context_files.append(result.file_name)
                                
                                context = "\n---\n".join(context_parts)
                                
                                # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
                                prompt_with_context = f"""
–¢—ã - –æ–ø—ã—Ç–Ω—ã–π —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∫–æ–¥–æ–≤—É—é –±–∞–∑—É. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

**–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ö–û–î–ê –†–ï–ü–û–ó–ò–¢–û–†–ò–Ø:**
{context}

**–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:**
{question}

**–ò–ù–°–¢–†–£–ö–¶–ò–ò:**
- –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–æ–¥–∞
- –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏
- –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è

**–û–¢–í–ï–¢:**
"""
                                
                                # 4. –í—ã–∑–æ–≤ OpenAI —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
                                if not analyzer.initialize_with_api_key(current_api_key):
                                    st.error("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI API")
                                else:
                                    try:
                                        response = analyzer.openai_manager.client.chat.completions.create(
                                            model=analyzer.openai_manager.model,
                                            messages=[
                                                {"role": "user", "content": prompt_with_context}
                                            ],
                                            temperature=0.1
                                        )
                                        
                                        answer = response.choices[0].message.content.strip()
                                        
                                        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                                        st.session_state.rag_chat_history.append((question, answer, context_files))
                                        
                                        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                                        st.success("‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!")
                                        st.rerun()
                                        
                                    except Exception as openai_error:
                                        st.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI API: {openai_error}")
                            else:
                                st.warning("üîç –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–¥–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.")
                                
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ Q&A: {e}")
                        logger.exception("–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Q&A")
            
            # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
            if st.session_state.rag_chat_history:
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", type="secondary"):
                    st.session_state.rag_chat_history = []
                    st.rerun()
    
    with tab3:
        st.header("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        if api_key:
            try:
                if analyzer.initialize_with_api_key(api_key):
                    token_stats = analyzer.openai_manager.get_token_usage_stats()
                    
                    st.metric(
                        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å–µ–≥–æ–¥–Ω—è", 
                        token_stats.get('used_today', 0),
                        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–æ–¥–Ω—è"
                    )
                else:
                    st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ OpenAI API")
            
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        else:
            st.info("‚ÑπÔ∏è –í–≤–µ–¥–∏—Ç–µ OpenAI API –∫–ª—é—á –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    
    with tab4:
        st.header("‚ùì –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        
        st.markdown("""
        ### üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä:
        
        1. **–ü–æ–ª—É—á–∏—Ç–µ OpenAI API –∫–ª—é—á:**
           - –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ [OpenAI Platform](https://platform.openai.com/)
           - –°–æ–∑–¥–∞–π—Ç–µ API –∫–ª—é—á –≤ —Ä–∞–∑–¥–µ–ª–µ "API Keys"
           - –í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
        
        2. **–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
           - –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∫–æ–¥–æ–º
           - –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤
        
        3. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑:**
           - –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑"
           - –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
           - –°–∫–∞—á–∞–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        
        ### üìã –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏:
        """)
        
        languages = {
            "Python": ".py",
            "JavaScript": ".js, .jsx", 
            "TypeScript": ".ts, .tsx",
            "Java": ".java",
            "C++": ".cpp, .cc, .cxx, .h, .hpp",
            "C#": ".cs",
            "Go": ".go",
            "Rust": ".rs",
            "PHP": ".php",
            "Ruby": ".rb"
        }
        
        for lang, ext in languages.items():
            st.write(f"‚Ä¢ **{lang}**: {ext}")
        
        st.markdown("""
        ### üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å:
        
        - **gpt-4.1-nano**: ~$0.001 –∑–∞ 1000 —Ç–æ–∫–µ–Ω–æ–≤
        - –°—Ä–µ–¥–Ω–∏–π —Ñ–∞–π–ª: ~500-1500 —Ç–æ–∫–µ–Ω–æ–≤
        - –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (20 —Ñ–∞–π–ª–æ–≤): ~$0.01-0.03
        
        ### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **gpt-4.1-nano** –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
        - –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        - –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤
        
        ### üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:
        
        - API –∫–ª—é—á –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è
        - –ö–æ–¥ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ OpenAI
        - –õ–æ–∫–∞–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """)


if __name__ == "__main__":
    main()
